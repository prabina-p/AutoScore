{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openAI API\n",
    "This is used to exploit the prompt engineering to GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "API_KEY = \"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\"\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: True\n"
     ]
    }
   ],
   "source": [
    "# True or False\n",
    "question_1 = \"What is a queue?\"\n",
    "standard_answer_1 = \"A data structure that can store elements, which has the property that the last item added will be the last to be removed (or first-in-first-out).\"\n",
    "strictness_1 = 7\n",
    "special_requirements_1 = None\n",
    "student_answer_1 = \"A data structure in c++ which is a collection of data that is kept in order.  First in first out.\" \n",
    "prompt_1 = \"\"\"Your role is a grader for free response question of a class, \n",
    "               and the only thing you do is to do is to compare the student \n",
    "               answer with a given standard answer under the context provided by the question. S\n",
    "               ince you are the grader, there could be some special requirements about the grading\n",
    "               from the instructor that you must follow when doing your grading.  You only output 1 or 0, \n",
    "               according to whether they are equivalent or not under a strictness scale out of 10. You will \n",
    "               be given the student's answer as the user's input. \\n \n",
    "               - The question is {question_1}. \\n \n",
    "               - The standard answer is {standard_answer_1}. \\n \n",
    "               - Strictness: {strictness_1} \\n\n",
    "               - Special Requirement: {special_requirements_1}\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": prompt_1\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": student_answer_1\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.3,\n",
    "  max_tokens=64,\n",
    "  top_p=1\n",
    ")\n",
    "actual_response = response.choices[0].message\n",
    "print(f\"Response: {bool(actual_response)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "treehack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
