{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import papermill as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# set n-gram N:\n",
    "N = 3 # default value, will get overwritten by papermill\n",
    "DATA_PATH = \"data/submission_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngram_features(data, n):\n",
    "    # Initialize CountVectorizer with desired n-gram range\n",
    "    vectorizer = CountVectorizer(ngram_range=(n, n), binary=True)\n",
    "    # Fit and transform the data\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    # Get feature names\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    return X, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Email</th>\n",
       "      <th>Status</th>\n",
       "      <th>Submission ID</th>\n",
       "      <th>Total Score</th>\n",
       "      <th>Max Points</th>\n",
       "      <th>Question 1 Score</th>\n",
       "      <th>Question 1 Weight</th>\n",
       "      <th>Question 1 Graded?</th>\n",
       "      <th>Question 1 Response</th>\n",
       "      <th>Question 1 Submitted At</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andrew Pan</td>\n",
       "      <td>A10001</td>\n",
       "      <td>andrep24@uw.edu</td>\n",
       "      <td>Ungraded</td>\n",
       "      <td>231798102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>Binary search trees represent a sophisticated ...</td>\n",
       "      <td>2024-02-17 14:04:35 -0800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name Student ID            Email    Status  Submission ID  \\\n",
       "0  Andrew Pan     A10001  andrep24@uw.edu  Ungraded      231798102   \n",
       "\n",
       "   Total Score  Max Points  Question 1 Score  Question 1 Weight  \\\n",
       "0          0.0         1.0               NaN                1.0   \n",
       "\n",
       "   Question 1 Graded?                                Question 1 Response  \\\n",
       "0               False  Binary search trees represent a sophisticated ...   \n",
       "\n",
       "     Question 1 Submitted At  \n",
       "0  2024-02-17 14:04:35 -0800  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Binary search trees represent a sophisticated data structure pivotal for managing and manipulating large datasets with optimal efficiency. Their function transcends simple storage; they offer a systematic arrangement of elements, allowing logarithmic time complexity for search operations through efficient partitioning of the data space. Furthermore, binary search trees facilitate dynamic operations such as insertion and deletion while maintaining their balanced structure, making them indispensable in domains where performance and scalability are paramount, such as database management systems and network routing algorithms.']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data = df['Question 1 Response'].tolist()\n",
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allowing logarithmic time</th>\n",
       "      <th>and deletion while</th>\n",
       "      <th>and manipulating large</th>\n",
       "      <th>and network routing</th>\n",
       "      <th>and scalability are</th>\n",
       "      <th>are paramount such</th>\n",
       "      <th>arrangement of elements</th>\n",
       "      <th>as database management</th>\n",
       "      <th>as insertion and</th>\n",
       "      <th>balanced structure making</th>\n",
       "      <th>...</th>\n",
       "      <th>them indispensable in</th>\n",
       "      <th>they offer systematic</th>\n",
       "      <th>through efficient partitioning</th>\n",
       "      <th>time complexity for</th>\n",
       "      <th>transcends simple storage</th>\n",
       "      <th>trees facilitate dynamic</th>\n",
       "      <th>trees represent sophisticated</th>\n",
       "      <th>where performance and</th>\n",
       "      <th>while maintaining their</th>\n",
       "      <th>with optimal efficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   allowing logarithmic time  and deletion while  and manipulating large  \\\n",
       "0                          1                   1                       1   \n",
       "\n",
       "   and network routing  and scalability are  are paramount such  \\\n",
       "0                    1                    1                   1   \n",
       "\n",
       "   arrangement of elements  as database management  as insertion and  \\\n",
       "0                        1                       1                 1   \n",
       "\n",
       "   balanced structure making  ...  them indispensable in  \\\n",
       "0                          1  ...                      1   \n",
       "\n",
       "   they offer systematic  through efficient partitioning  time complexity for  \\\n",
       "0                      1                               1                    1   \n",
       "\n",
       "   transcends simple storage  trees facilitate dynamic  \\\n",
       "0                          1                         1   \n",
       "\n",
       "   trees represent sophisticated  where performance and  \\\n",
       "0                              1                      1   \n",
       "\n",
       "   while maintaining their  with optimal efficiency  \n",
       "0                        1                        1  \n",
       "\n",
       "[1 rows x 76 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate n-gram features\n",
    "X, feature_names = generate_ngram_features(text_data, N)\n",
    "\n",
    "# Convert the result into a DataFrame for better visualization\n",
    "ngram_df = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "\n",
    "# Output the resulting DataFrame\n",
    "ngram_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus  import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score for n=0 -> 0.024175824175824177\n",
      "Accuracy Score for n=1 -> 0.6879120879120879\n",
      "Accuracy Score for n=2 -> 0.589010989010989\n",
      "Accuracy Score for n=3 -> 0.46813186813186813\n",
      "Accuracy Score for n=4 -> 0.33186813186813185\n",
      "Accuracy Score for n=5 -> 0.23516483516483516\n",
      "Accuracy Score for n=6 -> 0.16923076923076924\n",
      "Accuracy Score for n=7 -> 0.12307692307692308\n",
      "Accuracy Score for n=8 -> 0.1054945054945055\n",
      "Accuracy Score for n=9 -> 0.0945054945054945\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "def generate_ngram_tfidf_pipeline(data, labels, n):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer', CountVectorizer(ngram_range=(n, n), binary=True)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    # print(f'Classification Score for n={n} ->{classification_report(y_test, y_pred)}')\n",
    "    print(f'Accuracy Score for n={n} -> {accuracy_score(y_test, y_pred)}')\n",
    "\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def main():\n",
    "\n",
    "    def cleaning(df):\n",
    "        lowered=df.lower() # lowering the sentences \n",
    "        removed = re.sub(r'[^a-z]',' ',lowered)  # replacing the non alphabets with space \n",
    "        splitted=removed.split(' ')   # splitting the sentences by spaces to lemmatize\n",
    "        df = [WordNetLemmatizer().lemmatize(word) for word in splitted \n",
    "            if word not in stopwords.words('english')]  # lemmatizing and removing stopwords\n",
    "        df =' '.join(df) # joining back the words of list\n",
    "        return(removed)\n",
    "\n",
    "    csv_file = 'data/mohler_dataset_edited.csv'\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data['desired_answer'] = data['desired_answer'].apply(cleaning)\n",
    "    data['student_answer'] = data['student_answer'].apply(cleaning)\n",
    "\n",
    "    \n",
    "    text_data = data['student_answer'].tolist()\n",
    "    labels = data['desired_answer'].tolist() \n",
    "    \n",
    "    # n = 3\n",
    "    num_n = 10\n",
    "    for n in range(num_n):\n",
    "        generate_ngram_tfidf_pipeline(text_data, labels, n)\n",
    "\n",
    "    \n",
    "    # ngram_tfidf_pipeline = generate_ngram_tfidf_pipeline(text_data, labels, n)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
